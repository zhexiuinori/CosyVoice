# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import os
import sys
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append('{}/third_party/Matcha-TTS'.format(ROOT_DIR))

import argparse
import gradio as gr
import numpy as np
import torch
import torchaudio
import random
import librosa

import logging
logging.getLogger('matplotlib').setLevel(logging.WARNING)

from cosyvoice.cli.cosyvoice import CosyVoice
from cosyvoice.utils.file_utils import load_wav


logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s %(levelname)s %(message)s')

def generate_seed():
    seed = random.randint(1, 100000000)
    return {
        "__type__": "update",
        "value": seed
    }

def set_all_random_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

max_val = 0.8
def postprocess(speech, top_db=60, hop_length=220, win_length=440):
    speech, _ = librosa.effects.trim(
        speech, top_db=top_db,
        frame_length=win_length,
        hop_length=hop_length
    )
    if speech.abs().max() > max_val:
        speech = speech / speech.abs().max() * max_val
    speech = torch.concat([speech, torch.zeros(1, int(target_sr * 0.2))], dim=1)
    return speech

inference_mode_list = ['3sæé€Ÿå¤åˆ»', 'è·¨è¯­ç§å¤åˆ»']
instruct_dict = {'é¢„è®­ç»ƒéŸ³è‰²': '1. é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²\n2.ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®',
                 '3sæé€Ÿå¤åˆ»': '1. æœ¬åœ°ä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼Œæˆ–éº¦å…‹é£å½•å…¥\n2. è¾“å…¥å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬ä»¥åŠå¸Œæœ›å£°éŸ³å¤åˆ»çš„æ–‡æœ¬\n3.ç‚¹å‡»â€œä¸€é”®å¼€å¯å£°éŸ³å¤åˆ»ğŸ’•â€',
                 'è·¨è¯­ç§å¤åˆ»': '1. æœ¬åœ°ä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼Œæˆ–éº¦å…‹é£å½•å…¥\n2. **æ— éœ€è¾“å…¥**å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬\n3.ç‚¹å‡»â€œä¸€é”®å¼€å¯å£°éŸ³å¤åˆ»ğŸ’•â€',
                 'è‡ªç„¶è¯­è¨€æ§åˆ¶': '1. è¾“å…¥instructæ–‡æœ¬\n2.ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®'}
def change_instruction(mode_checkbox_group):
    return instruct_dict[mode_checkbox_group]

def generate_audio(tts_text, mode_checkbox_group, sft_dropdown, prompt_text, prompt_wav_upload, prompt_wav_record, instruct_text, seed):
    tts_text = "".join([item1 for item1 in tts_text.strip().split("\n") if item1 != ""]) + ".ã€‚"
    prompt_text = "".join([item2 for item2 in prompt_text.strip().split("\n") if item2 != ""])
    if prompt_wav_upload is not None:
        prompt_wav = prompt_wav_upload
    elif prompt_wav_record is not None:
        prompt_wav = prompt_wav_record
    else:
        prompt_wav = None
    # if instruct mode, please make sure that model is iic/CosyVoice-300M-Instruct and not cross_lingual mode
    if mode_checkbox_group in ['è‡ªç„¶è¯­è¨€æ§åˆ¶']:
        if cosyvoice.frontend.instruct is False:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, {}æ¨¡å‹ä¸æ”¯æŒæ­¤æ¨¡å¼, è¯·ä½¿ç”¨iic/CosyVoice-300M-Instructæ¨¡å‹'.format(args.model_dir))
            return (target_sr, default_data)
        if instruct_text == '':
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, è¯·è¾“å…¥instructæ–‡æœ¬')
            return (target_sr, default_data)
        if prompt_wav is not None or prompt_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, promptéŸ³é¢‘/promptæ–‡æœ¬ä¼šè¢«å¿½ç•¥')
    # if cross_lingual mode, please make sure that model is iic/CosyVoice-300M and tts_text prompt_text are different language
    if mode_checkbox_group in ['è·¨è¯­ç§å¤åˆ»']:
        if cosyvoice.frontend.instruct is True:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, {}æ¨¡å‹ä¸æ”¯æŒæ­¤æ¨¡å¼, è¯·ä½¿ç”¨iic/CosyVoice-300Mæ¨¡å‹'.format(args.model_dir))
            return (target_sr, default_data)
        if instruct_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥')
        if prompt_wav is None:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, è¯·æä¾›promptéŸ³é¢‘')
            return (target_sr, default_data)
        gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, è¯·ç¡®ä¿åˆæˆæ–‡æœ¬å’Œpromptæ–‡æœ¬ä¸ºä¸åŒè¯­è¨€')
    # if in zero_shot cross_lingual, please make sure that prompt_text and prompt_wav meets requirements
    if mode_checkbox_group in ['3sæé€Ÿå¤åˆ»', 'è·¨è¯­ç§å¤åˆ»']:
        if prompt_wav is None:
            gr.Warning('promptéŸ³é¢‘ä¸ºç©ºï¼Œæ‚¨æ˜¯å¦å¿˜è®°è¾“å…¥promptéŸ³é¢‘ï¼Ÿ')
            return (target_sr, default_data)
        if torchaudio.info(prompt_wav).sample_rate < prompt_sr:
            gr.Warning('promptéŸ³é¢‘é‡‡æ ·ç‡{}ä½äº{}'.format(torchaudio.info(prompt_wav).sample_rate, prompt_sr))
            return (target_sr, default_data)
    # sft mode only use sft_dropdown
    if mode_checkbox_group in ['é¢„è®­ç»ƒéŸ³è‰²']:
        if instruct_text != '' or prompt_wav is not None or prompt_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨é¢„è®­ç»ƒéŸ³è‰²æ¨¡å¼ï¼Œpromptæ–‡æœ¬/promptéŸ³é¢‘/instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥ï¼')
    # zero_shot mode only use prompt_wav prompt text
    if mode_checkbox_group in ['3sæé€Ÿå¤åˆ»']:
        if prompt_text == '':
            gr.Warning('promptæ–‡æœ¬ä¸ºç©ºï¼Œæ‚¨æ˜¯å¦å¿˜è®°è¾“å…¥promptæ–‡æœ¬ï¼Ÿ')
            return (target_sr, default_data)
        if instruct_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨3sæé€Ÿå¤åˆ»æ¨¡å¼ï¼Œé¢„è®­ç»ƒéŸ³è‰²/instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥ï¼')

    if mode_checkbox_group == 'é¢„è®­ç»ƒéŸ³è‰²':
        logging.info('get sft inference request')
        set_all_random_seed(seed)
        output = cosyvoice.inference_sft(tts_text, sft_dropdown)
    elif mode_checkbox_group == '3sæé€Ÿå¤åˆ»':
        logging.info('get zero_shot inference request')
        prompt_speech_16k = postprocess(load_wav(prompt_wav, prompt_sr))
        set_all_random_seed(seed)
        output = cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k)
    elif mode_checkbox_group == 'è·¨è¯­ç§å¤åˆ»':
        logging.info('get cross_lingual inference request')
        prompt_speech_16k = postprocess(load_wav(prompt_wav, prompt_sr))
        set_all_random_seed(seed)
        output = cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k)
    else:
        logging.info('get instruct inference request')
        set_all_random_seed(seed)
        output = cosyvoice.inference_instruct(tts_text, sft_dropdown, instruct_text)
    audio_data = output['tts_speech'].numpy().flatten()
    return (target_sr, audio_data)

def main():
    with gr.Blocks() as demo:
        gr.Markdown("# <center>ğŸŒŠğŸ’•ğŸ¶ [CosyVoice](https://www.bilibili.com/video/BV1vz421q7ir/) 3ç§’éŸ³é¢‘ï¼Œå¼€å¯æœ€å¼ºå£°éŸ³å¤åˆ»</center>")
        gr.Markdown("## <center>ğŸŒŸ åªéœ€3ç§’å‚è€ƒéŸ³é¢‘ï¼Œä¸€é”®å¼€å¯è¶…æ‹ŸäººçœŸå®å£°éŸ³å¤åˆ»ï¼Œæ”¯æŒä¸­æ—¥è‹±éŸ©ç²¤è¯­ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒï¼</center>")
        gr.Markdown("### <center>ğŸ¤— æ›´å¤šç²¾å½©ï¼Œå°½åœ¨[æ»”æ»”AI](https://www.talktalkai.com/)ï¼›æ»”æ»”AIï¼Œä¸ºçˆ±æ»”æ»”ï¼ğŸ’•</center>")

        with gr.Row():
            tts_text = gr.Textbox(label="è¯·å¡«å†™æ‚¨å¸Œæœ›å£°éŸ³å¤åˆ»çš„æ–‡æœ¬å†…å®¹", lines=3, placeholder="æƒ³è¯´å´è¿˜æ²¡è¯´çš„ï¼Œè¿˜å¾ˆå¤š...")
            mode_checkbox_group = gr.Radio(choices=inference_mode_list, label='è¯·é€‰æ‹©å£°éŸ³å¤åˆ»ç±»å‹', value=inference_mode_list[0])
            instruction_text = gr.Text(label="ğŸ“” æ“ä½œæŒ‡å—", value=instruct_dict[inference_mode_list[0]], scale=0.5)
            sft_dropdown = gr.Dropdown(choices=sft_spk, label='é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²', value=sft_spk[0], scale=0.25, visible=False)
            with gr.Column(scale=0.25):
                seed_button = gr.Button(value="\U0001F3B2", visible=True)
                seed = gr.Number(value=0, label="éšæœºæ¨ç†ç§å­", info="è‹¥æ•°å€¼ä¿æŒä¸å˜ï¼Œåˆ™æ¯æ¬¡ç”Ÿæˆç»“æœä¸€è‡´", visible=True)

        with gr.Row():
            prompt_text = gr.Textbox(label="è¯·å¡«å†™å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬å†…å®¹", lines=3, placeholder="å‘Šè¯‰æˆ‘å‚è€ƒéŸ³é¢‘è¯´äº†äº›ä»€ä¹ˆå§...")
            prompt_wav_upload = gr.Audio(sources='upload', type='filepath', label='è¯·ä»æœ¬åœ°ä¸Šä¼ æ‚¨å–œæ¬¢çš„å‚è€ƒéŸ³é¢‘ï¼Œæ³¨æ„é‡‡æ ·ç‡ä¸ä½äº16kHz')
            prompt_wav_record = gr.Audio(sources='microphone', type='filepath', label='é€šè¿‡éº¦å…‹é£å½•åˆ¶å‚è€ƒéŸ³é¢‘ï¼Œç¨‹åºä¼šä¼˜å…ˆä½¿ç”¨æœ¬åœ°ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘')
            generate_button = gr.Button("ä¸€é”®å¼€å¯å£°éŸ³å¤åˆ»ğŸ’•", variant="primary")
        instruct_text = gr.Textbox(label="è¾“å…¥instructæ–‡æœ¬", lines=1, placeholder="è¯·è¾“å…¥instructæ–‡æœ¬.", value='', visible=False)


        audio_output = gr.Audio(label="ä¸ºæ‚¨ç”Ÿæˆçš„ä¸“å±éŸ³é¢‘ğŸ¶")

        seed_button.click(generate_seed, inputs=[], outputs=seed)
        generate_button.click(generate_audio,
                              inputs=[tts_text, mode_checkbox_group, sft_dropdown, prompt_text, prompt_wav_upload, prompt_wav_record, instruct_text, seed],
                              outputs=[audio_output])
        mode_checkbox_group.change(fn=change_instruction, inputs=[mode_checkbox_group], outputs=[instruction_text])
        gr.Markdown("### <center>æ³¨æ„â—ï¼šè¯·ä¸è¦ç”Ÿæˆä¼šå¯¹ä¸ªäººä»¥åŠç»„ç»‡é€ æˆä¾µå®³çš„å†…å®¹ï¼Œæ­¤ç¨‹åºä»…ä¾›ç§‘ç ”ã€å­¦ä¹ åŠä¸ªäººå¨±ä¹ä½¿ç”¨ã€‚è¯·è‡ªè§‰åˆè§„ä½¿ç”¨æ­¤ç¨‹åºï¼Œç¨‹åºå¼€å‘è€…ä¸è´Ÿæœ‰ä»»ä½•è´£ä»»ã€‚</center>")
        gr.HTML('''
            <div class="footer">
                        <p>ğŸŒŠğŸï¸ğŸ¶ - æ±Ÿæ°´ä¸œæµæ€¥ï¼Œæ»”æ»”æ— å°½å£°ã€‚ æ˜Â·é¡¾ç’˜
                        </p>
            </div>
        ''')
    demo.queue()
    demo.launch(share=True, show_error=True)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--port',
                        type=int,
                        default=8000)
    parser.add_argument('--model_dir',
                        type=str,
                        default='iic/CosyVoice-300M',
                        help='local path or modelscope repo id')
    args = parser.parse_args()
    cosyvoice = CosyVoice(args.model_dir)
    sft_spk = cosyvoice.list_avaliable_spks()
    prompt_sr, target_sr = 16000, 22050
    default_data = np.zeros(target_sr)
    main()
